{"cells":[{"cell_type":"code","execution_count":20,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-06T18:40:36.888585Z","iopub.status.busy":"2022-09-06T18:40:36.887645Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["   39          State-gov   77516   Bachelors   13        Never-married  \\\n","0  50   Self-emp-not-inc   83311   Bachelors   13   Married-civ-spouse   \n","1  38            Private  215646     HS-grad    9             Divorced   \n","2  53            Private  234721        11th    7   Married-civ-spouse   \n","3  28            Private  338409   Bachelors   13   Married-civ-spouse   \n","4  37            Private  284582     Masters   14   Married-civ-spouse   \n","\n","         Adm-clerical   Not-in-family   White     Male   2174   0   40  \\\n","0     Exec-managerial         Husband   White     Male      0   0   13   \n","1   Handlers-cleaners   Not-in-family   White     Male      0   0   40   \n","2   Handlers-cleaners         Husband   Black     Male      0   0   40   \n","3      Prof-specialty            Wife   Black   Female      0   0   40   \n","4     Exec-managerial            Wife   White   Female      0   0   40   \n","\n","    United-States   <=50K  \n","0   United-States   <=50K  \n","1   United-States   <=50K  \n","2   United-States   <=50K  \n","3            Cuba   <=50K  \n","4   United-States   <=50K  \n","[' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' >50K' ' <=50K']\n","Confusion matrix for LogisticRegression model : [[5855  330]\n"," [1317  638]]\n","Classification report for LogisticRegression model               precision    recall  f1-score   support\n","\n","       <=50K       0.82      0.95      0.88      6185\n","        >50K       0.66      0.33      0.44      1955\n","\n","    accuracy                           0.80      8140\n","   macro avg       0.74      0.64      0.66      8140\n","weighted avg       0.78      0.80      0.77      8140\n","\n","[' >50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' <=50K']\n","Classification report for DecisionTree model               precision    recall  f1-score   support\n","\n","       <=50K       0.86      0.95      0.90      6185\n","        >50K       0.76      0.52      0.62      1955\n","\n","    accuracy                           0.84      8140\n","   macro avg       0.81      0.73      0.76      8140\n","weighted avg       0.84      0.84      0.83      8140\n","\n","Confusion matrix for DecisionTree model  [[5859  326]\n"," [ 941 1014]]\n","accuracy score 0.8525798525798526\n","[' >50K' ' <=50K' ' <=50K' ... ' <=50K' ' >50K' ' <=50K']\n","Confusion matrix for RandomForestClassifier model  [[5716  469]\n"," [ 731 1224]]\n","Classification report for RandomForestClassifier model               precision    recall  f1-score   support\n","\n","       <=50K       0.89      0.92      0.91      6185\n","        >50K       0.72      0.63      0.67      1955\n","\n","    accuracy                           0.85      8140\n","   macro avg       0.80      0.78      0.79      8140\n","weighted avg       0.85      0.85      0.85      8140\n","\n","accuracy score 0.7863636363636364\n","[' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' >50K' ' <=50K']\n","Confusion matrix for KNN model  [[5825  360]\n"," [1379  576]]\n","Classification report for KNN model               precision    recall  f1-score   support\n","\n","       <=50K       0.81      0.94      0.87      6185\n","        >50K       0.62      0.29      0.40      1955\n","\n","    accuracy                           0.79      8140\n","   macro avg       0.71      0.62      0.63      8140\n","weighted avg       0.76      0.79      0.76      8140\n","\n","[' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' >50K' ' <=50K']\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["accuracy score 0.8008599508599509\n","[' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' <=50K']\n","Confusion matrix for SVC model  [[6117   68]\n"," [1553  402]]\n","Classification report for SVC model               precision    recall  f1-score   support\n","\n","       <=50K       0.80      0.99      0.88      6185\n","        >50K       0.86      0.21      0.33      1955\n","\n","    accuracy                           0.80      8140\n","   macro avg       0.83      0.60      0.61      8140\n","weighted avg       0.81      0.80      0.75      8140\n","\n","Training score 0.7961916461916462\n","Test score 0.8008599508599509\n","accuracy score for LogisticRegression 0.7976658476658477\n","The percentage misclassification is 20.23341523341523\n","accuracy score for DecisionTree 0.8443488943488944\n","The percentage misclassification is 15.565110565110562\n","accuracy score for RandomForestClassifier 0.8525798525798526\n","The percentage misclassification is 14.742014742014742\n","accuracy score for KNN 0.7863636363636364\n","The percentage misclassification is 21.363636363636363\n","accuracy score for SVC 0.8008599508599509\n","The percentage misclassification is 19.914004914004913\n","Since  KNNClassifier  has the best accuracy_score, it is the most accurate model\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to loa\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","import numpy as np # linear algebra\n","from sklearn import metrics\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.model_selection import cross_val_score\n","\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","import csv\n","df=pd.DataFrame()\n","df=pd.read_csv(\"C:/Users/HP/Downloads/adult.csv\")\n","\n","\n","\n","print(df.head())\n","\n","df.columns=('Age','Workclass','Fnlwgt','Education','education_num','martial_status','occupation','relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country','income')\n","\n","df=df.replace('?', 'null')#replacing question marks with 'null' \n","\n","\n","\n","\n","\n","y=df.income\n","\n","\n","\n","x=df.drop('income',axis=1)\n","\n","\n","x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n","\n","x_train=pd.get_dummies(x_train)\n","\n","x_test=pd.get_dummies(x_test)\n","x_train,x_test = x_train.align(x_test,join='inner',axis=1)\n","x_train=x_train.replace('null', np.nan)\n","x_test=x_test.replace('null', np.nan)\n","\n","\n","x_train=SimpleImputer(strategy='mean').fit_transform(x_train)\n","\n","x_test=SimpleImputer(strategy='mean').fit_transform(x_test)\n","\n","\n","m1=LogisticRegression(max_iter=1000)\n","m1.fit(x_train,y_train)\n","\n","\n","m1.fit(x_test,y_test)\n","\n","ypred=m1.predict(x_test)\n","print(ypred)\n","cm=metrics.confusion_matrix(y_test,ypred)\n","print(\"Confusion matrix for LogisticRegression model :\",cm)\n","print(\"Classification report for LogisticRegression model\",metrics.classification_report(y_test,ypred))\n","m2=DecisionTreeClassifier(criterion='gini',max_depth=4,min_samples_split=12)\n","m2.fit(x_train,y_train)\n","\n","\n","ypred2=m2.predict(x_test)\n","print(ypred2)\n","cm=metrics.confusion_matrix(y_test,ypred2)\n","print(\"Classification report for DecisionTree model\",metrics.classification_report(y_test,ypred2))\n","print(\"Confusion matrix for DecisionTree model \",cm)\n","m3=RandomForestClassifier(n_estimators=100,criterion='entropy',random_state=0)\n","m3.fit(x_train,y_train)\n","print(\"accuracy score\",accuracy_score(y_test, m3.predict(x_test)))\n","ypred3=m3.predict(x_test)\n","print(ypred3)\n","cm=metrics.confusion_matrix(y_test,ypred3)\n","print(\"Confusion matrix for RandomForestClassifier model \",cm)\n","print(\"Classification report for RandomForestClassifier model\",metrics.classification_report(y_test,ypred3))\n","\n","knn = KNeighborsClassifier(n_neighbors=7)\n","knn.fit(x_train,y_train)\n","print(\"accuracy score\",accuracy_score(y_test, knn.predict(x_test)))\n","knn.predict(x_test)\n","print(knn.predict(x_test))\n","cm=metrics.confusion_matrix(y_test,knn.predict(x_test))\n","print(\"Confusion matrix for KNN model \",cm)\n","print(\"Classification report for KNN model\",metrics.classification_report(y_test,knn.predict(x_test)))\n","print(knn.predict(x_test))\n","\n","m4 = LinearSVC(random_state=0, tol=1e-5)\n","m4.fit(x_train, y_train) \n","\n","print(\"accuracy score\",accuracy_score(y_test, m4.predict(x_test)))\n","ypred4=m4.predict(x_test)\n","print(ypred4)\n","cm=metrics.confusion_matrix(y_test,ypred4)\n","print(\"Confusion matrix for SVC model \",cm)\n","print(\"Classification report for SVC model\",metrics.classification_report(y_test,ypred4))\n","print('Training score',m4.score(x_train,y_train))\n","print('Test score',m4.score(x_test,y_test))\n","\n","print(\"accuracy score for LogisticRegression\",accuracy_score(y_test, m1.predict(x_test)))\n","ascore1=accuracy_score(y_test, m1.predict(x_test))\n","pscore1=precision_score(y_test, m1.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","fscore1=f1_score(y_test, m1.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","rscore1=recall_score(y_test, m1.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","misclasspercent1=(1-ascore1)*100\n","print(\"The percentage misclassification is\",misclasspercent1)\n","print(\"accuracy score for DecisionTree\",accuracy_score(y_test, m2.predict(x_test)))\n","ascore2=accuracy_score(y_test, m2.predict(x_test))\n","pscore2=precision_score(y_test, m2.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","fscore2=f1_score(y_test, m2.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","rscore2=recall_score(y_test, m2.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","misclasspercent2=(1-ascore2)*100\n","print(\"The percentage misclassification is\",misclasspercent2)\n","print(\"accuracy score for RandomForestClassifier\",accuracy_score(y_test, m3.predict(x_test)))\n","ascore3=accuracy_score(y_test, m3.predict(x_test))\n","pscore3=precision_score(y_test, m3.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","fscore3=f1_score(y_test, m3.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","rscore3=recall_score(y_test, m3.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","misclasspercent3=(1-ascore3)*100\n","print(\"The percentage misclassification is\",misclasspercent3)\n","print(\"accuracy score for KNN\",accuracy_score(y_test, knn.predict(x_test)))\n","ascorek=accuracy_score(y_test, knn.predict(x_test))\n","pscorek=precision_score(y_test, knn.predict(x_test), pos_label=\" <=50K\")\n","fscorek=f1_score(y_test, knn.predict(x_test), pos_label=\" <=50K\")\n","rscorek=recall_score(y_test, knn.predict(x_test), pos_label=\" <=50K\")\n","misclasspercentk=(1-ascorek)*100\n","print(\"The percentage misclassification is\",misclasspercentk)\n","print(\"accuracy score for SVC\",accuracy_score(y_test, m4.predict(x_test)))\n","ascore4=accuracy_score(y_test, m4.predict(x_test))\n","pscore4=precision_score(y_test, m4.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","fscore4=f1_score(y_test, m4.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","rscore4=recall_score(y_test, m4.predict(x_test),average=\"binary\", pos_label=\" <=50K\")\n","misclasspercent4=(1-ascore4)*100\n","print(\"The percentage misclassification is\",misclasspercent4)\n","l=['ascore1','ascore2','ascore3','ascorek','ascore4']\n","l1=['LogisticRegression','DecisionTree','RandomForestClassifier','KNNClassifier','SVCClassifier']\n","max_item = l.index(max(l))\n","                     \n","  \n","print(\"Since \",l1[max_item],\" has the best accuracy_score, it is the most accurate model\")\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"}}},"nbformat":4,"nbformat_minor":4}
